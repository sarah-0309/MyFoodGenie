# -*- coding: utf-8 -*-
"""Myfoodgenie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1chj58d-5DAM6IFZmA8WfQAllg2wGQDmH

#MyFoodGenie - Food Recommendation System

##Sarah Kim

## Content Based Filtering & Collaborative Filtering

Content-based Filtering: Will recommend food items based on their attributes (like C_Type, Veg_Non, Describe). If a user liked a particular type of food, I can recommend other foods with similar attributes.

Collaborative Filtering: Will consider the ratings given by users to recommend similar food items based on other users' preferences. For instance, if User A and User B both liked a particular food item, and User A liked another food item, then that item might be recommended to User B.

##Data Prep
"""

import pandas as pd
import numpy as np

food_data = pd.read_csv('/dataset.csv')
ratings_data = pd.read_csv('/ratings.csv')

food_data.info()

"""###Food Data (dataset.csv):

Food_ID: Identifier for the food item.

Name: Name of the food item.

C_Type: Type or category of the food (e.g., Healthy Food, Snack, Dessert).

Veg_Non: Vegetarian or Non-Vegetarian classification.

Describe: Ingredients or a brief description of the food.
"""

food_data.head()

food_data.shape

food_data.duplicated().sum() #Any duplicated data? - no

ratings_data.info()

"""###Ratings Data (ratings.csv):

User_ID: Identifier for the user.

Food_ID: Identifier for the food item (links to the Food Data).

Rating: The rating given by the user for the food item.

"""

ratings_data.head()

ratings_data.shape

ratings_data.duplicated().sum() #Any duplicated data? - no

"""#Content-Based Filtering

###TfIdfVectorizer
"""

# Compute TF-IDF vectors for each food item's combined attributes
tfidf_vectorizer = TfidfVectorizer(stop_words='english') #remove some unnecessary words
tfidf_matrix = tfidf_vectorizer.fit_transform(food_data['combined_attributes'])

tfidf_matrix.shape #400 describe attribute contains 1175 words

# Compute the cosine similarity between food items

from sklearn.metrics.pairwise import linear_kernel

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

cosine_sim.shape

"""The cosine similarity matrix has been computed successfully. It has a shape of
400Ã—400, which means we have computed the similarity for 400 food items against each other

###Creating a function to get recommendations based on a given food item

This function will provide a list of food items that are most similar to the given item based on the computed cosine similarities.
"""

# Get the index of the given food item - Just considering the Food names from the dataframe

index = pd.Series(food_data.index, index=food_data['Name']).drop_duplicates()
index #The resulting indices Series can be used to look up the row index of a particular Name value in df1 by using the Series' .loc accessor.

index['chicken minced salad']

food_data.iloc[[1]]

# Get the top 10 lists when getting the Food Name
def get_recommendations(Name, cosine_sim=cosine_sim):

# Get the index through Food Name in whole data
  idx = index[Name]

# Get data as (idc,sim) in (cosine_sim) -  Get the pairwise similarity scores of all food items with the given item
  sim_scores = list(enumerate(cosine_sim[idx]))

# Get in reverse order based on sim score
  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

# 10 food recommendations exclding oneself
  sim_scores = sim_scores[1:11]

# 10 index info in food
  food_index = [i[0] for i in sim_scores]

# Return the top 10 most similar food items
  return food_data['Name'].iloc[food_index]

"""###TEST"""

# Test the function with a sample food item
recommendations = get_recommendations("summer squash salad")
recommendations

"""The function has provided the top 10 recommended food items based on the given food item "summer squash salad". Here are the recommendations:

Green cucumber shots

Shepherds salad (Tamatar-Kheera Salaad)

Amaranthus granola with lemon yogurt, berries, and honey

Baked namakpara with roasted almond dip

Shrimp & cilantro ceviche

Grilled Chicken with Almond and Garlic Sauce

Spanish fish fry

Oats shallots pulao

Coffee marinated mutton chops

Roast turkey with cranberry sauce

##Recommendation Based on 'C_Type' and 'Veg_Non'
"""

food_data.head(3)

food_data.loc[0, 'C_Type']

def data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(' ', '')) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(' ', ''))
        else:
            return ''

features = ['C_Type', 'Veg_Non']
for feature in features:
    food_data[feature] = food_data[feature].apply(data)

food_data[['Name', 'C_Type', 'Veg_Non']].head(3)

def create_soup(x):
    return ''.join(x['C_Type']) + ' ' + ''.join(x['Veg_Non'])
food_data['soup'] = food_data.apply(create_soup, axis=1)
food_data['soup']

from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(food_data['soup'])
count_matrix

from sklearn.metrics.pairwise import cosine_similarity
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)
cosine_sim2

index['summer squash salad']

food_data = food_data.reset_index()
index = pd.Series(food_data.index, index=food_data['Name'])
index

"""### LET'S TEST HOW IT WORKS"""

get_recommendations('summer squash salad', cosine_sim2)

food_data.loc[0] #data of summer squash salad

food_data.loc[3] #data of tricolour salad

"""both summer squash salad and tricolour salad are healthyfood and veg"""

get_recommendations('christmas cake', cosine_sim2)

"""#Collaborative Filtering

##Data Prep
"""

pip install -r requirements.txt
import pickle
import streamlit as st
streamlit
scikit-surprise
... (any other libraries you're using)

import surprise
surprise.__version__

import pandas as pd
from surprise import Reader, Dataset, SVD
from surprise.model_selection import cross_validate, train_test_split

ratings_data.head()

#Checking the shape
ratings_data.shape

# Checking for null values
ratings_data.isnull().sum()

ratings_data = ratings_data.dropna()

ratings_data.isnull().sum()

ratings_data['Rating'].min()

ratings_data['Rating'].max()

reader = Reader(rating_scale=(1, 10))

data = Dataset.load_from_df(ratings_data[['User_ID', 'Food_ID', 'Rating']], reader=reader)
data

"""## Cross Validate(RMSE, MAE)

###K-Fold
"""

svd = SVD(random_state=0)

cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

"""cv = 5 (divide data into 5 datasests)

100 data

A:1-20

B:21-40

C:41-60

D:61-80

E:81-100

ABCD (train set) E (test set)

ABCE (train set) D (test set)

ABDE (train set) C (test set)

ACDE (train set) B (test set)

BCDE (train set) A (test set)
"""

trainset = data.build_full_trainset()
svd.fit(trainset)

ratings_data[ratings_data['User_ID'] == 1] #how userid = 1 rated the food

svd.predict(1, 12) # predict how would userid = 1 rate foodid = 12 -> est = 10 might rate 10

svd.predict(1, 300, 3) # User_ID = 1 real rated score is 3 for Food_ID = 300, how would it be the predicted score? -> est = 10

"""apparently this isn't accurate, I think bc the data is small"""

ratings_data[ratings_data['User_ID'] == 100]

svd.predict(100, 300) # User_Id = 100, Food_Id = 300

"""userid 100 would rate 10 for foodid 300"""
